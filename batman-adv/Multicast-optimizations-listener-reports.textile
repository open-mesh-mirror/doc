h1. Multicast Optimizations -â€¯Considerations for IGMP/MLD Reports

h2. Scenario

!{width: 80%;}basic-multicast-listener-mldv1report.png!

_A multicast listener announcing it's presence via a MLDv1 report_

Hosts wanting to receive multicast traffic of a specific group announce this via IGMP/MLD reports. This way multicast routers and snooping switches/bridges are able to learn where which multicast packets are wanted.

h3. Goals

* Preventing packetloss on bridges (once multicast-bridge-support is implemented)

h3. The Problem

* MLD/IGMP reports not arriving at bridges, bridges dropping multicast packets

The destination address of MLDv1/IGMPv2 reports (in this example "ff12::123") is usually one a multicast router or snooping switch/bridge is not listening to: They are not able to actively join every possible multicast group. So only checking the multicast addresses in the translation table and forward the report to nodes matching the destination address would not be enough in the scenario described above. Node L needing to send a report after the querier (here: on the node with the bridge) asked for it would simply drop the report.

!{width: 80%;}basic-multicast-listener-mldv1report-canceled.png!

_Neither the Querier nor the Sender are listening to "ff12::123"_

This in turn would result in the bridge not forwarding the multicast data from the sender behind its bridge port even though a listener exists:

!{width: 80%;}basic-multicast-listener-mldv1report-canceled-data.png!

_Bridge dropping packets bc. of missing reports_

Note that even though MLDv2/IGMPv3 require listeners to report to the all-multicast-routers destination address (ff02::16, 224.0.0.22) the querier implementation in the Linux bridge code does not listen to them which creates the same problem as with MLDv1/IGMPv2. "RFC4541":http://tools.ietf.org/html/rfc4541 ("Considerations for Internet Group Management Protocol (IGMP) and Multicast Listener Discovery (MLD) Snooping Switches") leaves it open whether snooping switches/bridges (with or without a querier) should listen to the all-multicast-routers destination address.

h3. Solution

h4. Flooding Report Messages

One easy approach is to simply flood multicast reports to all other batman-adv nodes.

_Advantages:_

 * Simplicity:
 ** No multicast query snooping needed, only multicast report snooping
 ** No state for querier

_Disadvantages:_

 * Multicast report overhead for every node (both throughput and memory)
 * Might cause issues for switches if more than 4k hosts on the network: Usually the MAC table of hardware switches only allows up to 4k clients (there are batman-adv networks with 1.5k hosts already).
 * Central querier(s)

(Yet another simple approach to tackle these disadvantages could be through segmenting the IGMP/MLD domain. The OpenWRT-based firmware framework "Gluon", aiming at wireless community mesh networks, currently has a patchset for this pending: https://github.com/freifunk-gluon/gluon/pull/402)

----

h3. Alternative Solutions

h4. Snooping Queries and MRD

RFC4541, section 2.1.1.1) recommends sending all reports directly and only to multicast routers. Can be determined via IGMP/MLD querier and MRD (Multicast Router Discovery) Multicast Router Advertisements.

A simple implementation could do the following: Snoop these messages coming from the mesh and memorize their originators. Forward IGMP/MLD reports to these nodes only then.

_Advantages:_

 * Low(er) MLD/IGMP traffic and memory overhead for batman-adv and the bridge

_Disadvantages:_

 * Every node has the multicast query parsing burdon
 * Central querier(s)

h4. WANT_ALL_{IGMP,MLD}_REPORTS flag

Instead of having the query and MRD RA parsing burdon on multicast traffic coming from the mesh (mesh-ingress), having it on the mesh-egress side instead. Compared to the proposed solution, the advantage would be a better Denial-of-Service robustness. The disadvantage is increased complexity (yet another flag and counter).

h4. IGMP/MLD proxying

Proxy the IGMP/MLD between the local segment and the rest of the mesh. batman-adv would participate as a multicast querier on its local segment only and would generate multicast reports from the multicast addresses in the global translation table. Requirement: More flexible and generic translation table, in that being able to store IPv4+IPv6 addresses instead of just MAC addresses, too.

----

h4. Side note 1: Why does the current implementation without bridge support have no such issues?

There are usually two parties interested in multicast listener reports. For one thing, bridges ("software switches") and snooping switches (enterprise hardware switches). For another thing, multicast routers want IGMP/MLD reports. If the former, a bridge, exists then multicast optimizations are disabled at the moment, so the issue can't occure. For the latter, reports to multicast routers, let's consider the following two cases:

a) Multicast listeners joining a link-local address
b) Multicast listeners joining a non-link-local address

Multicast routers need reports to learn and tell other routers about multicast traffic their part of the network is interested in. Link-local multicast is not routed, so multicast routers aren't actually interested in reports of case a). For b), the current implementation in batman-adv is flooding multicast packets with a routable destination everywhere unconditionally. IGMPv2/MLDv1 reports for routable traffic have a routable multicast destination, so every node and therefore any potential multicast router will receive them.

h4. Side note 2: Compatibility Concerns

As described above, while there is no issue for the current implementation as is it faces compatibility issues with any upcoming bridge integration. Bridged nodes need to be able to rely on any other node, including non-bridged / "old" ones, to forward its own reports properly.

To avoid packet loss, bridged nodes will force any old node to hand over any reports. This is done by increasing the multicast tvlv version number to two:

!{width: 80%;}basic-multicast-listener-mldv1report-mcast-versions.png!

_Mesh consisting of both old (mcast tvlv v1) and new (mcast tvlv v2) nodes_

From the perspective of an old node with insufficient report handling and multicast tvlv version one the bridged node will then appear to be incapable of announcing its own listeners.

!{width: 80%;}basic-multicast-listener-mldv1report-mcast-versions-search.png!

_An old node looking for nodes without an mcast v1 tvlv_

The old node will turn off its own multicast optimizations and flood any multicast packet, including reports:

!{width: 80%;}basic-multicast-listener-mldv1report-mcast-versions-flood.png!

_An old node flooding its reports_


To avoid regressions for non-bridged setups currently relying on multicast optimizations, the following is done: Any node _without_ a bridge but capable of proper report handling will register both a multicast tvlv version one and two:

!{width: 80%;}basic-multicast-listener-mldv1report-mcast-versions-nobridge.png!

_A mesh without bridges: New nodes announcing both v1 and v2_